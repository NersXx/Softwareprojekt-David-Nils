{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de82a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote .npz files to data_npz\n"
     ]
    }
   ],
   "source": [
    "# convert_to_npz.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SRC = Path(\"B/time_series\")\n",
    "OUT = Path(\"data_npz\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "LABELS = pd.read_csv(\"B/labels.csv\")  # must contain patient_id or filename + label\n",
    "\n",
    "# normalize labels: accept column \"filename\" or \"patient_id\"\n",
    "if \"filename\" in LABELS.columns:\n",
    "    LABELS[\"patient_id\"] = LABELS[\"filename\"].str.replace(r\"\\.csv$\", \"\", regex=True)\n",
    "elif \"patient_id\" not in LABELS.columns:\n",
    "    raise SystemExit(\"labels.csv must contain 'patient_id' or 'filename' column\")\n",
    "\n",
    "label_map = dict(zip(LABELS[\"patient_id\"].astype(str), LABELS[\"label\"].astype(int)))\n",
    "\n",
    "for csv_path in sorted(SRC.glob(\"*.csv\")):\n",
    "    pid = csv_path.stem\n",
    "    df = pd.read_csv(csv_path)            # simple read; adjust read_csv args if needed\n",
    "    # optional: ensure consistent column order here if you want\n",
    "    X = df.to_numpy(dtype=np.float32)     # shape (T, F)\n",
    "    y = label_map.get(pid, -1)            # -1 if missing label\n",
    "    np.savez_compressed(OUT / f\"{pid}.npz\", X=X, y=np.int8(y))\n",
    "print(\"Done. Wrote .npz files to\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab8fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data_npz\\p100001.npz\n",
      "Label y: 0\n",
      "Shape (T, F): (23, 40)\n",
      "Dtype: float32\n",
      "Total elements: 920\n",
      "Number of NaNs: 629\n",
      "\n",
      "First 8 rows:\n",
      "[[  93.     92.5      nan  110.     76.     56.     22.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    2.  ]\n",
      " [  91.     96.       nan  108.     84.5    72.     23.5      nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan  233.       nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    3.  ]\n",
      " [  93.     98.       nan  123.     87.     61.     21.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    4.  ]\n",
      " [  93.     95.       nan  110.     81.     70.     20.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    5.  ]\n",
      " [    nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    6.  ]\n",
      " [  91.5    97.     36.5   104.     75.     60.     20.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    7.  ]\n",
      " [  94.     95.       nan  114.     85.     66.     20.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan  154.       nan    2.1      nan    3.7      nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    8.  ]\n",
      " [  94.     95.       nan  121.     88.     69.     20.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64    9.  ]]\n",
      "Last 8 rows:\n",
      "[[  94.     93.       nan  114.     84.     63.     16.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan  123.       nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   17.  ]\n",
      " [  98.     97.       nan  116.     84.     63.     22.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   18.  ]\n",
      " [  98.     99.     36.9   121.     86.     62.     18.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   19.  ]\n",
      " [ 105.     95.       nan  106.     76.     55.     18.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   20.  ]\n",
      " [  96.     93.       nan  110.     81.     62.     16.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   21.  ]\n",
      " [ 102.     96.       nan  115.     85.     67.     18.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   22.  ]\n",
      " [ 105.     97.     37.    108.     83.     69.     16.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan  123.       nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   23.  ]\n",
      " [ 107.     92.       nan  116.     87.     70.     16.       nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
      "      nan     nan     nan     nan     nan     nan     nan   73.      1.\n",
      "     1.      0.   -214.64   24.  ]]\n"
     ]
    }
   ],
   "source": [
    "# view_npz_matrix.py\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "FILE = Path(\"data_npz/p100001.npz\")  # adjust if needed\n",
    "\n",
    "def load(file: Path):\n",
    "    arr = np.load(file, allow_pickle=True)\n",
    "    X = arr[\"X\"] if \"X\" in arr.files else None\n",
    "    y = arr[\"y\"].item() if \"y\" in arr.files else None\n",
    "    extras = {k: arr[k] for k in arr.files if k not in (\"X\", \"y\")}\n",
    "    return X, y, extras\n",
    "\n",
    "def print_overview(X, y, extras):\n",
    "    print(\"File:\", FILE)\n",
    "    print(\"Label y:\", y)\n",
    "    if X is None:\n",
    "        print(\"No 'X' array found.\")\n",
    "        return\n",
    "    print(\"Shape (T, F):\", X.shape)\n",
    "    print(\"Dtype:\", X.dtype)\n",
    "    print(\"Total elements:\", X.size)\n",
    "    print(\"Number of NaNs:\", int(np.isnan(X).sum()))\n",
    "    if extras:\n",
    "        print(\"Extra arrays in file:\", list(extras.keys()))\n",
    "    print()\n",
    "\n",
    "def show_full(X):\n",
    "    # Only use if matrix is reasonably small\n",
    "    np.set_printoptions(threshold=100000, precision=4, suppress=True)\n",
    "    print(X)\n",
    "\n",
    "def show_head(X, n=10):\n",
    "    print(f\"First {n} rows:\")\n",
    "    print(X[:n])\n",
    "\n",
    "def show_tail(X, n=10):\n",
    "    print(f\"Last {n} rows:\")\n",
    "    print(X[-n:])\n",
    "\n",
    "def show_as_dataframe(X, extras):\n",
    "    # If feature names exist in extras, use them\n",
    "    cols = None\n",
    "    if \"feature_names\" in extras:\n",
    "        try:\n",
    "            cols = [str(x) for x in extras[\"feature_names\"].tolist()]\n",
    "        except Exception:\n",
    "            cols = None\n",
    "    if cols is None:\n",
    "        cols = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=cols)\n",
    "    print(df.head(20))  # show first 20 rows in table form\n",
    "\n",
    "def main():\n",
    "    X, y, extras = load(FILE)\n",
    "    print_overview(X, y, extras)\n",
    "    if X is None:\n",
    "        return\n",
    "\n",
    "    # Choose one of the following inspection methods:\n",
    "    # 1) Safe quick view\n",
    "    show_head(X, n=8)\n",
    "    # 2) Tail\n",
    "    show_tail(X, n=8)\n",
    "    # 3) Pretty table if you want column names\n",
    "    # show_as_dataframe(X, extras)\n",
    "    # 4) Full print only if small\n",
    "    # show_full(X)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb88afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HospData:\n",
    "\n",
    "    class InvalidData(Exception):\n",
    "        def __init__(self):\n",
    "            pass\n",
    "            \n",
    "        def __str__(self):\n",
    "            return f\"Something went wrong\\n\"\n",
    "        \n",
    "        \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "           \n",
    "        \n",
    "    def extract_data(self):\n",
    "        \"\"\"returns data_train, data_validation, data_test\"\"\"\n",
    "        try:\n",
    "            data_train = jnp.array(self.dataset[\"data_train\"])\n",
    "            data_validation = jnp.array(self.dataset[\"data_validation\"])\n",
    "            data_test = jnp.array(self.dataset[\"data_test\"])\n",
    "        except Exception as e:\n",
    "            raise self.InvalidData(self.dataset)\n",
    "        \n",
    "        return data_train, data_validation,  data_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "try:\n",
    "    TrainD = HospData(np.load(''))\n",
    "    TestD = HospData(np.load(''))\n",
    "    ValD = HospData(np.load(''))\n",
    "except Exception as e:\n",
    "    raise e\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f726cc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data_npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     84\u001b[39m     ValD = HospData(np.load(\u001b[33m'\u001b[39m\u001b[33mdata_npz\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m#print the shape of the data arrays\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     TrainD = HospData(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_npz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     83\u001b[39m     TestD = HospData(np.load(\u001b[33m'\u001b[39m\u001b[33mdata_npz\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     84\u001b[39m     ValD = HospData(np.load(\u001b[33m'\u001b[39m\u001b[33mdata_npz\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nilsl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:451\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    449\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'data_npz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Mapping, Union\n",
    "\n",
    "class HospData:\n",
    "    class InvalidData(Exception):\n",
    "        def __init__(self, info=None):\n",
    "            self.info = info\n",
    "        def __str__(self):\n",
    "            return \"Something went wrong\\n\" + (str(self.info) if self.info is not None else \"\")\n",
    "\n",
    "    def __init__(self, dataset: Union[Mapping, str, Path], seed: int = 42):\n",
    "        \"\"\"\n",
    "        dataset: entweder ein Mapping mit keys\n",
    "                 'data_train','data_validation','data_test' (numpy arrays),\n",
    "                 oder ein Pfad zu einem Ordner mit per-patient .npz Dateien (je Datei: 'X' und 'y').\n",
    "        \"\"\"\n",
    "        if isinstance(dataset, (str, Path)):\n",
    "            self.dataset = self._build_from_dir(Path(dataset), seed)\n",
    "        elif isinstance(dataset, Mapping):\n",
    "            self.dataset = dataset\n",
    "        else:\n",
    "            raise TypeError(\"dataset must be a mapping or a path to a directory\")\n",
    "\n",
    "    def _build_from_dir(self, folder: Path, seed: int):\n",
    "        files = sorted(folder.glob(\"*.npz\"))\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No .npz files in {folder}\")\n",
    "        ids = [p.stem for p in files]\n",
    "        random.Random(seed).shuffle(ids)\n",
    "\n",
    "        n = len(ids)\n",
    "        n_train = int(n * 0.8)\n",
    "        n_val = int(n * 0.1)\n",
    "        train_ids = ids[:n_train]\n",
    "        val_ids = ids[n_train:n_train + n_val]\n",
    "        test_ids = ids[n_train + n_val:]\n",
    "\n",
    "        def load_list(id_list):\n",
    "            seqs = []\n",
    "            for pid in id_list:\n",
    "                arr = np.load(folder / f\"{pid}.npz\", allow_pickle=True)\n",
    "                if \"X\" not in arr.files:\n",
    "                    raise KeyError(f\"'X' not in {pid}.npz\")\n",
    "                seqs.append(arr[\"X\"].astype(np.float32))\n",
    "            return seqs\n",
    "\n",
    "        X_train = load_list(train_ids)\n",
    "        X_val = load_list(val_ids)\n",
    "        X_test = load_list(test_ids)\n",
    "\n",
    "        # pad to global max length\n",
    "        all_seqs = X_train + X_val + X_test\n",
    "        T_max = max(x.shape[0] for x in all_seqs)\n",
    "        F = all_seqs[0].shape[1]\n",
    "\n",
    "        def pad(seqs):\n",
    "            out = np.zeros((len(seqs), T_max, F), dtype=np.float32)\n",
    "            for i, s in enumerate(seqs):\n",
    "                out[i, : s.shape[0], :] = s\n",
    "            return out\n",
    "\n",
    "        return {\n",
    "            \"data_train\": pad(X_train),\n",
    "            \"data_validation\": pad(X_val),\n",
    "            \"data_test\": pad(X_test)\n",
    "        }\n",
    "\n",
    "    def extract_data(self):\n",
    "        \"\"\"returns data_train, data_validation, data_test as jnp arrays\"\"\"\n",
    "        try:\n",
    "            dt = jnp.array(self.dataset[\"data_train\"])\n",
    "            dv = jnp.array(self.dataset[\"data_validation\"])\n",
    "            dte = jnp.array(self.dataset[\"data_test\"])\n",
    "        except Exception as e:\n",
    "            raise self.InvalidData(e)\n",
    "        return dt, dv, dte\n",
    "#print the shape of the data arrays\n",
    "try:\n",
    "    TrainD = HospData(np.load('data_npz'))\n",
    "    TestD = HospData(np.load('data_npz'))\n",
    "    ValD = HospData(np.load('data_npz'))\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
