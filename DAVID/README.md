# Softwareproject by David Daniel Rosas Marquez

Hello and welcome to my part of the Softwareproject. In the Following Text I'll give a brief overview of my work throughout the semester, that I did for the course "Softwareprojekt: Machinelles Learnen f√ºr Lebenswissenschaftliche Daten". But first a couple of notes:

---

## Notes

1) This folder doesn't contain all of the scripts I wrote throughout the semester, just the ones I thought are the most relevant to the course and the "final attempts" for each project. I'll also always specify the files that need to be run and in which order, and if specific folder structures are needed to be able to reproduce the intended output.

2) A lot of the python scripts are extensively commented (especially for the first couple projcets). I chose to leave the comments in, because they were part of my process to try and better understand certain machine learning concepts (As I was completely new to the topic), and to rationalize what was happening in the code. But this also means that a lot of the comments might contain unclear or outright wrong statements, a lot of typos, grammar errors, redundancy and so on. This goes especially for comments where I am trying to understand/explain certain concepts.

3) The naming conventions for classes and variables and the coding style can be somewhat inconsistent. The code structure for the projects is also somewhat messy and not necessarily optimaly modular. I hope this doesn't cause too much confusion.

4) I divided my work into Projects called "Project_x" that thematically fit together. Some of them took multiple attempts or multiple weeks, but I decided to only upload the final working versions. I did this to provide an easier to follow overview of my work thoughout this semester.

---

With this in mind now follows the Overview.

---

# PROJECT 0

The First couple of weeks for me mostly involved getting into the topic of machine learning and artificial neural networks. For this we first implemented a simple linear regression using gradient descent, a technique also used for learning in neural networks. In the script "linear_regression.py" (can run on it's own) the idea is to interpolate some data points that follow a simple linear function with noise. Some diagrams for the loss surface are also plotted, to better be able to visualize the effects of gradient descent. 
The other project is in the script "digit_recog.py", which contains code for a simple multilayer perceptron trained to recognize digits from the mnist_784 dataset. This project got me to learn the basics of machine learning and artificial neural networks.
During the first couple of weeks we also had to do some reading on some more complex NODE models, for which I chose the ACE_NODE. In "ACE_NODE.odp" you can see the slides for the presentation I made on the topic.

**difficulties:**  
EVERYTHING. Especially trying to build the sufficient understanding to begin to tackle the concepts inside the paper "ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential
Equations"

**learned:**  
- What is a neural network
- Forward Pass and Backpropagation (superficially)  
- how do neural networks "learn" using gradient descent  
- How to code and train a basic neural network
- Basics of classification tasks

---

# PROJECT 1

**difficulties:**

**learned:**

---

# PROJECT 2

**difficulties:**

**learned:**

---

# PROJECT 3

**difficulties:**

**learned:**

---

# PROJECT 4

**difficulties:**

**learned:**

---

# PROJECT 5

**difficulties:**

**learned:**
